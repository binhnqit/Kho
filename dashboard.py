import streamlit as st
import pandas as pd
import plotly.express as px
from supabase import create_client
from datetime import datetime

# --- 1. K·∫æT N·ªêI H·ªÜ TH·ªêNG ---
url = "https://cigbnbaanpebwrufzxfg.supabase.co"
key = st.secrets["SUPABASE_KEY"]
supabase = create_client(url, key)

# --- 2. H√ÄM X·ª¨ L√ù D·ªÆ LI·ªÜU (HARDENED LOGIC) ---
@st.cache_data(ttl=30)
def load_repair_data_final():
    try:
        # L·∫•y d·ªØ li·ªáu m·ªõi nh·∫•t t·ª´ Supabase (S·∫Øp x·∫øp theo th·ªùi gian t·∫°o h·ªá th·ªëng)
        res = supabase.table("repair_cases") \
            .select("*") \
            .order("created_at", desc=True) \
            .execute()
            
        if not res.data: 
            return pd.DataFrame()
        
        df = pd.DataFrame(res.data)

        # Chuy·ªÉn ƒë·ªïi datetime v√† b·ªçc l·ªói
        df['confirmed_dt'] = pd.to_datetime(df['confirmed_date'], errors='coerce')
        df['created_dt']   = pd.to_datetime(df['created_at'], errors='coerce')
        df = df.dropna(subset=['confirmed_dt'])

        # Tr√≠ch xu·∫•t chi·ªÅu th·ªùi gian (D√πng cho B√°o c√°o & AI)
        df['NƒÇM'] = df['confirmed_dt'].dt.year.astype(int)
        df['TH√ÅNG'] = df['confirmed_dt'].dt.month.astype(int)
        
        day_map = {'Monday': 'Th·ª© 2', 'Tuesday': 'Th·ª© 3', 'Wednesday': 'Th·ª© 4',
                   'Thursday': 'Th·ª© 5', 'Friday': 'Th·ª© 6', 'Saturday': 'Th·ª© 7', 'Sunday': 'Ch·ªß Nh·∫≠t'}
        df['TH·ª®'] = df['confirmed_dt'].dt.day_name().map(day_map)

        # L√†m s·∫°ch s·ªë li·ªáu chi ph√≠
        df['CHI_PH√ç'] = pd.to_numeric(df['compensation'], errors='coerce').fillna(0)
        
        # Lu√¥n ∆∞u ti√™n hi·ªÉn th·ªã record m·ªõi n·∫°p l√™n ƒë·∫ßu
        df = df.sort_values(by='created_dt', ascending=False)
        return df
    except Exception as e:
        st.error(f"L·ªói h·ªá th·ªëng t·∫£i data: {e}")
        return pd.DataFrame()

# --- 3. GIAO DI·ªÜN CH√çNH ---
def main():
    st.set_page_config(page_title="4ORANGES OPS 2026", layout="wide", page_icon="üé®")
    
    # Load d·ªØ li·ªáu t·ªïng
    df_db = load_repair_data_final()

    # --- TABS CH·ª®C NƒÇNG ---
    tab_dash, tab_admin, tab_ai = st.tabs(["üìä B√ÅO C√ÅO V·∫¨N H√ÄNH", "üì• QU·∫¢N TR·ªä H·ªÜ TH·ªêNG", "üß† AI INSIGHTS"])

    # --- TAB 1: B√ÅO C√ÅO V·∫¨N H√ÄNH ---
    with tab_dash:
        if df_db.empty:
            st.info("Ch∆∞a c√≥ d·ªØ li·ªáu. Vui l√≤ng n·∫°p ·ªü Tab Qu·∫£n tr·ªã.")
        else:
            with st.sidebar:
                st.header("‚öôÔ∏è B·ªò L·ªåC")
                if st.button("üîÑ L√ÄM M·ªöI D·ªÆ LI·ªÜU", use_container_width=True):
                    st.cache_data.clear()
                    st.rerun()
                
                filter_mode = st.radio("Ch·∫ø ƒë·ªô l·ªçc:", ["Theo Th√°ng/NƒÉm", "Theo Kho·∫£ng ng√†y"])

                if filter_mode == "Theo Th√°ng/NƒÉm":
                    available_years = sorted(df_db['NƒÇM'].unique(), reverse=True)
                    sel_year = st.selectbox("üìÖ Ch·ªçn nƒÉm", options=available_years)
                    available_months = sorted(df_db[df_db['NƒÇM'] == sel_year]['TH√ÅNG'].unique().tolist())
                    sel_month = st.selectbox("üìÜ Ch·ªçn th√°ng", options=["T·∫•t c·∫£"] + available_months)
                    
                    df_view = df_db[df_db['NƒÇM'] == sel_year].copy()
                    if sel_month != "T·∫•t c·∫£":
                        df_view = df_view[df_view['TH√ÅNG'] == sel_month]
                        # T√≠nh Delta so v·ªõi th√°ng tr∆∞·ªõc
                        prev_m = sel_month - 1 if sel_month > 1 else 12
                        prev_y = sel_year if sel_month > 1 else sel_year - 1
                        df_prev = df_db[(df_db['NƒÇM'] == prev_y) & (df_db['TH√ÅNG'] == prev_m)]
                    else:
                        df_prev = pd.DataFrame()
                else:
                    date_range = st.date_input("Ch·ªçn kho·∫£ng ng√†y", value=[df_db['confirmed_dt'].min(), df_db['confirmed_dt'].max()])
                    if len(date_range) == 2:
                        df_view = df_db[(df_db['confirmed_dt'].dt.date >= date_range[0]) & (df_db['confirmed_dt'].dt.date <= date_range[1])].copy()
                    df_prev = pd.DataFrame()

            # --- KPI METRICS ---
            st.title("üöÄ Ch·ªâ S·ªë V·∫≠n H√†nh")
            c1, c2, c3 = st.columns(3)
            curr_cost = df_view['CHI_PH√ç'].sum()
            if not df_prev.empty:
                delta = curr_cost - df_prev['CHI_PH√ç'].sum()
                c1.metric("üí∞ T·ªîNG CHI PH√ç", f"{curr_cost:,.0f} ƒë", delta=f"{delta:,.0f} ƒë", delta_color="inverse")
            else:
                c1.metric("üí∞ T·ªîNG CHI PH√ç", f"{curr_cost:,.0f} ƒë")
            
            c2.metric("üõ†Ô∏è S·ªê CA", f"{len(df_view)} ca")
            top_b = df_view['branch'].value_counts().idxmax() if not df_view.empty else "N/A"
            c3.metric("üè¢ ƒêI·ªÇM N√ìNG", top_b)

            # --- CHARTS ---
            st.divider()
            col_left, col_right = st.columns([6, 4])
            with col_left:
                st.subheader("üìÖ Xu h∆∞·ªõng s·ª± v·ª• theo th·ª©")
                order = ['Th·ª© 2', 'Th·ª© 3', 'Th·ª© 4', 'Th·ª© 5', 'Th·ª© 6', 'Th·ª© 7', 'Ch·ªß Nh·∫≠t']
                day_stats = df_view['TH·ª®'].value_counts().reindex(order).fillna(0).reset_index()
                st.plotly_chart(px.area(day_stats, x='index', y='TH·ª®', markers=True), use_container_width=True)
            
            with col_right:
                st.subheader("üö® Ca chi ph√≠ cao")
                st.table(df_view.nlargest(5, 'CHI_PH√ç')[['confirmed_dt', 'machine_id', 'CHI_PH√ç']])

    # --- TAB 2: QU·∫¢N TR·ªä (Sub-tabs & Rollback) ---
    with tab_admin:
        st.title("üì• Qu·∫£n Tr·ªã D·ªØ Li·ªáu")
        s1, s2 = st.tabs(["‚ûï NH·∫¨P LI·ªÜU", "üìú L·ªäCH S·ª¨ BATCH"])
        
        with s1:
            c_up, c_man = st.columns(2)
            with c_up:
                st.subheader("üìÇ CSV Import")
                up_file = st.file_uploader("Ch·ªçn file", type="csv")
                if up_file:
                    df_up = pd.read_csv(up_file)
                    batch_id = f"B_{datetime.now().strftime('%m%d%H%M')}"
                    df_up['batch_id'] = batch_id
                    df_up['created_at'] = datetime.now().isoformat()
                    if st.button(f"X√°c nh·∫≠n n·∫°p L√¥ {batch_id}"):
                        supabase.table("repair_cases").upsert(df_up.to_dict(orient='records')).execute()
                        st.cache_data.clear()
                        st.rerun()
            with c_man:
                st.subheader("‚úçÔ∏è Nh·∫≠p tay")
                with st.form("f_man"):
                    f_m = st.text_input("M√£ m√°y")
                    f_c = st.number_input("Chi ph√≠", min_value=0)
                    if st.form_submit_button("L∆∞u ca m·ªõi"):
                        # Logic insert t∆∞∆°ng t·ª±...
                        st.success("ƒê√£ l∆∞u!")

    # --- TAB 3: AI INSIGHTS (ENTERPRISE HARDENED) ---
    with tab_ai:
        st.title("üß† Tr·ª£ L√Ω AI Ph√¢n T√≠ch")
        
        # 1. Hardening Data
        cost_series = df_db['CHI_PH√ç'].dropna()
        if len(cost_series) < 10:
            st.warning("‚ö†Ô∏è D·ªØ li·ªáu qu√° m·ªèng ƒë·ªÉ AI ph√¢n t√≠ch. C·∫ßn t·ªëi thi·ªÉu 10 ca.")
            st.stop()

        ai_1, ai_2, ai_3 = st.tabs(["üö© C·∫¢NH B√ÅO", "üèóÔ∏è R·ª¶I RO THI·∫æT B·ªä", "üìä D·ª∞ B√ÅO"])

        with ai_1:
            # Anomaly Detection (2-Sigma)
            threshold = cost_series.mean() + 2 * cost_series.std()
            anomalies = df_db[df_db['CHI_PH√ç'] > threshold]
            if not anomalies.empty:
                st.error(f"Ph√°t hi·ªán {len(anomalies)} ca v∆∞·ª£t ng∆∞·ª°ng chi ph√≠ an to√†n!")
                st.dataframe(anomalies[['confirmed_dt', 'machine_id', 'CHI_PH√ç']])
            else:
                st.success("Kh√¥ng ph√°t hi·ªán b·∫•t th∆∞·ªùng v·ªÅ chi ph√≠.")

        with ai_2:
            # Risk Scoring (Normalized)
            m_stats = df_db.groupby('machine_id').agg(count=('machine_id','count'), cost=('CHI_PH√ç','sum')).reset_index()
            # Normalize v·ªÅ thang 0-1
            m_stats['freq_norm'] = m_stats['count'] / m_stats['count'].max()
            m_stats['cost_norm'] = m_stats['cost'] / m_stats['cost'].max()
            m_stats['risk_score'] = (m_stats['freq_norm'] * 0.6 + m_stats['cost_norm'] * 0.4).round(2)
            
            st.plotly_chart(px.bar(m_stats.nlargest(10, 'risk_score'), x='risk_score', y='machine_id', orientation='h', title="Top 10 M√°y R·ªßi Ro Cao (ƒê√£ Normalize)"))

        with ai_3:
            # Forecast & Latest Month Fix
            monthly = df_db.groupby(['NƒÇM', 'TH√ÅNG'])['CHI_PH√ç'].sum().reset_index()
            if len(monthly) >= 2:
                # D√πng MAX ƒë·ªÉ l·∫•y th√°ng m·ªõi nh·∫•t
                latest_data = monthly.sort_values(['NƒÇM', 'TH√ÅNG']).iloc[-1]
                curr_month_val = latest_data['CHI_PH√ç']
                forecast_val = monthly['CHI_PH√ç'].rolling(3, min_periods=1).mean().iloc[-1]
                
                # B·ªçc chia cho 0
                diff = ((forecast_val / curr_month_val) - 1) * 100 if curr_month_val > 0 else 0
                
                c_f1, c_f2 = st.columns(2)
                c_f1.metric("D·ª± b√°o th√°ng t·ªõi", f"{forecast_val:,.0f} ƒë")
                c_f2.metric("Bi·∫øn ƒë·ªông d·ª± ki·∫øn", f"{diff:.1f}%", delta=f"{diff:.1f}%", delta_color="inverse")

            # NLP Parser nh·∫π
            st.divider()
            q = st.text_input("üí¨ H·ªèi AI (V√≠ d·ª•: 'M√°y n√†o h·ªèng ·ªü Mi·ªÅn B·∫Øc?')")
            if q:
                branch_key = "Mi·ªÅn B·∫Øc" if "b·∫Øc" in q.lower() else "Mi·ªÅn Nam" if "nam" in q.lower() else None
                if branch_key:
                    res_q = df_db[df_db['branch'] == branch_key]['machine_id'].value_counts()
                    st.info(f"ü§ñ V√πng {branch_key}: M√°y {res_q.index[0]} h·ªèng nhi·ªÅu nh·∫•t ({res_q.values[0]} l·∫ßn).")

if __name__ == "__main__":
    main()
