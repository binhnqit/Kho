import streamlit as st
import pandas as pd
# Gi·∫£ s·ª≠ b·∫°n c√†i ƒë·∫∑t: pip install supabase
from supabase import create_client 

# --- CONFIG SUPABASE (Thay b·∫±ng th√¥ng tin c·ªßa b·∫°n) ---
# Th∆∞·ªùng c√°c th√¥ng tin n√†y n√™n ƒë·ªÉ trong st.secrets ƒë·ªÉ b·∫£o m·∫≠t
SUPABASE_URL = st.secrets.get("SUPABASE_URL", "https://your-project.supabase.co")
SUPABASE_KEY = st.secrets.get("SUPABASE_KEY", "your-anon-key")
supabase = create_client(SUPABASE_URL, SUPABASE_KEY)

# --- III. ƒê·ªäNH NGHƒ®A SCHEMA CHU·∫®N ---
FILE_1_COLUMNS = [
    "M√É S·ªê M√ÅY", "KHU V·ª∞C", "LO·∫†I M√ÅY", "T√åNH TR·∫†NG",
    "NG√ÄY NH·∫¨N", "KI·ªÇM TRA TH·ª∞C T·∫æ", "S·ª¨A N·ªòI B·ªò",
    "S·ª¨A B√äN NGO√ÄI", "NG√ÄY S·ª¨A XONG", "S·ª¨A ƒê·ªÄN B√ô",
    "GIAO L·∫†I Mi·ªÅn B·∫Øc", "NG√ÄY TR·∫¢", "H∆Ø KH√îNG S·ª¨A ƒê∆Ø·ª¢C"
]

FILE_2_COLUMNS = [
    "M√£ s·ªë m√°y", "T√™n KH", "L√Ω Do", "Ghi Ch√∫",
    "Chi Nh√°nh", "Ng√†y X√°c nh·∫≠n",
    "Ng∆∞·ªùi Ki·ªÉm Tra", "Chi Ph√≠ D·ª± Ki·∫øn", "Chi Ph√≠ Th·ª±c T·∫ø"
]

# --- IV. H√ÄM VALIDATION & LOGGING ---
def validate_csv(df, expected_columns):
    errors = []
    missing = set(expected_columns) - set(df.columns)
    if missing:
        errors.append(f"‚ùå Thi·∫øu c·ªôt: {', '.join(missing)}")
    if df.empty:
        errors.append("‚ùå File kh√¥ng c√≥ d·ªØ li·ªáu")
    return errors

def log_audit(action, detail):
    try:
        supabase.table("audit_logs").insert({
            "actor": "admin_user", # C√≥ th·ªÉ thay b·∫±ng st.experimental_user n·∫øu c√≥ login
            "action": action,
            "target": "csv_import",
            "diff": detail,
            "created_at": datetime.datetime.now().isoformat()
        }).execute()
    except Exception as e:
        st.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ ghi log: {e}")

# --- V. H√ÄM INSERT D·ªÆ LI·ªÜU ---
def import_file_1(df):
    progress_bar = st.progress(0)
    for i, r in df.iterrows():
        # 1. UPSERT MACHINE (N·∫øu c√≥ m√£ m√°y r·ªìi th√¨ c·∫≠p nh·∫≠t, ch∆∞a th√¨ th√™m m·ªõi)
        machine_res = supabase.table("machines").upsert({
            "machine_code": str(r["M√É S·ªê M√ÅY"]),
            "machine_type": r["LO·∫†I M√ÅY"],
            "region": r["KHU V·ª∞C"]
        }).execute()
        
        # 2. CREATE REPAIR CASE
        case_data = {
            "machine_code": str(r["M√É S·ªê M√ÅY"]),
            "received_date": str(r["NG√ÄY NH·∫¨N"]),
            "is_unrepairable": "H∆Ø" in str(r["H∆Ø KH√îNG S·ª¨A ƒê∆Ø·ª¢C"]).upper(),
            "compensation": "ƒê·ªÄN B√ô" in str(r["S·ª¨A ƒê·ªÄN B√ô"]).upper()
        }
        supabase.table("repair_cases").insert(case_data).execute()
        
        progress_bar.progress((i + 1) / len(df))
    st.success(f"‚úÖ ƒê√£ ƒë·ªìng b·ªô {len(df)} d√≤ng v√†o Core Data.")

def import_file_2(df):
    progress_bar = st.progress(0)
    for i, r in df.iterrows():
        # Insert v√†o b·∫£ng chi ph√≠ (Finance)
        finance_data = {
            "machine_code": str(r["M√£ s·ªë m√°y"]),
            "customer_name": r["T√™n KH"],
            "issue_description": r["L√Ω Do"],
            "confirmed_date": str(r["Ng√†y X√°c nh·∫≠n"]),
            "estimated_cost": float(str(r["Chi Ph√≠ D·ª± Ki·∫øn"]).replace(',', '') or 0),
            "actual_cost": float(str(r["Chi Ph√≠ Th·ª±c T·∫ø"]).replace(',', '') or 0),
            "confirmed_by": r["Ng∆∞·ªùi Ki·ªÉm Tra"]
        }
        supabase.table("finance_records").insert(finance_data).execute()
        progress_bar.progress((i + 1) / len(df))
    st.success(f"‚úÖ ƒê√£ c·∫≠p nh·∫≠t d·ªØ li·ªáu t√†i ch√≠nh cho {len(df)} m√°y.")

# --- VI. T√çCH H·ª¢P V√ÄO TAB M·ªöI ---
# C·∫≠p nh·∫≠t d√≤ng khai b√°o tabs trong h√†m main():
# tabs = st.tabs(["üìä XU H∆Ø·ªöNG", "üí∞ T√ÄI CH√çNH", "ü©∫ S·ª®C KH·ªéE", "üì¶ LOGISTICS", "üß† AI", "üì• DATA INGESTION"])

def render_ingestion_tab(tabs):
    with tabs[5]: # Tab DATA INGESTION
        st.subheader("üì• DATA INGESTION ‚Äì CSV IMPORT")
        
        col_up1, col_up2 = st.columns([1, 2])
        with col_up1:
            file_type = st.selectbox(
                "Ch·ªçn lo·∫°i file d·ªØ li·ªáu",
                ["FILE 1 ‚Äì THEO D√ïI S·ª¨A CH·ªÆA", "FILE 2 ‚Äì CHI PH√ç & X√ÅC NH·∫¨N"]
            )
            st.info("üí° H·ªá th·ªëng y√™u c·∫ßu ƒë√∫ng 100% ƒë·ªãnh d·∫°ng c·ªôt ƒë·ªÉ ƒë·∫£m b·∫£o t√≠nh to√†n v·∫πn d·ªØ li·ªáu.")

        with col_up2:
            uploaded_file = st.file_uploader("Upload file CSV", type=["csv"])

        if uploaded_file:
            # ƒê·ªçc file
            df_upload = pd.read_csv(uploaded_file).fillna("")
            
            # Ki·ªÉm tra schema
            expected = FILE_1_COLUMNS if "FILE 1" in file_type else FILE_2_COLUMNS
            errors = validate_csv(df_upload, expected)

            if errors:
                for e in errors: st.error(e)
                st.stop()
            
            st.success("‚úÖ File h·ª£p l·ªá. Xem tr∆∞·ªõc 5 d√≤ng d·ªØ li·ªáu:")
            st.dataframe(df_upload.head(5), use_container_width=True)

            # N√∫t th·ª±c thi Import
            if st.button("üöÄ B·∫ÆT ƒê·∫¶U IMPORT V√ÄO DATABASE", type="primary"):
                with st.spinner("ƒêang ghi d·ªØ li·ªáu v√†o Supabase..."):
                    if "FILE 1" in file_type:
                        import_file_1(df_upload)
                    else:
                        import_file_2(df_upload)
                    
                    # Audit log
                    log_audit("IMPORT_CSV", {
                        "file": uploaded_file.name,
                        "type": file_type,
                        "rows": len(df_upload)
                    })
                    
                    st.balloons()
                    st.info("üìú Audit log ƒë√£ ƒë∆∞·ª£c ghi nh·∫≠n h·ªá th·ªëng.")
